---
title: "Public Health Analysis using DP Data"
author: "David Van Riper"
date: "9/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

## Differential Privacy and the Decennial Census 

In August 2018, the US Census Bureau announced it would adopt a new method to protect respondent confidentiality in the 2020 Decennial Census of Population and Housing (Abowd 2018). Instead of using techniques such as cell suppression or household swapping (footnote McKenna's paper), the Bureau will use a technique based on differential privacy to protect confidentiality. ADD IN QUOTE FROM GARFINKEL ABOUT SEA CHANGE IN DATA PUBLICATION.

Why did the Bureau decide to change its disclosure avoidance system? Bureau scientists executed a reconstruction and reidentification attack on the publicly available tabulations from the 2010 decennial census. Using the database reconstruction theorem, the Bureau reconstructed 308,745,538 person records from census tract and block data. 



### Policy Decisions

Disclosure avoidance algorithms require parameters that control the amount of noise, suppression, or swapping applied to the input data. Values for these parameters impact the quality and accuracy of the output data, and it is critical that data users understand both the significance of the parameters and their possible range of values. This section discusses the Top Down Algorithm's parameters and the values used to generate the DDP and the v20200527 datasets. 

#### Global Privacy Loss Budget

The global privacy loss budget ($\epsilon$) controls the trade-off between the privacy afforded to Census respondents and the accuracy of the published data. Values for $\epsilon$ range from 0 to infinity, with 0 representing perfect privacy/no accuracy and infinity representing no privacy/perfect accuracy. After establishing the global PLB, it is then allocated to geographic levels and queries. Geographic levels or queries that receive larger fractions will be more accurate. 

For both the DDP and v20200527 datasets, the Census Bureau's Data Stewardship Executive Policy Committee established a PLB of 4.0 for person-based tables.^[The DDP included housing unit and household data. A PLB of 2.0 was provided housing unit-based queries. The v20200527 only includes person data.] The PLB was then allocated to combinations of geographic levels and queries, and those allocations ultimately control the magnitude of the noise injected into counts.  

#### Geographic Levels

If we think of the cross-tabulations into which noise is injected as a set of rows and columns, the geographic levels define the rows. Each row in a cross-tabulation is a geographic unit within a geographic level (e.g., Autauga County, Alabama, is a geographic unit in the County geographic level). For both the DDP and v20200527 datasets, seven geographic levels in the Census Bureau's hierarchy received direct allocations of the PLB. The nation and state received 20% each, and the remaining five levels (county, census tract group^[The census tract group is not a standard unit in the Census Bureau's geographic hierarchy. It was created specifically for the disclosure avoidance system to control the number of child units for each county], census tract, block group, and block) received 12% each. Geographic levels that receive no direct PLB allocation accumulate accuracy from the units that comprise them.

#### Queries 

If geographic levels define the rows of a cross-tabulation, then queries define the columns. Queries are essentially combinations of demographic variables, and the PLB is allocated to these queries. The disclosure avoidance system defined two types of queries. "Detailed" queries consist of all unique combinations of variables, and "DP" queries are specific combinations of variables. The "detailed" queries allow the Bureau to reconstruct the underlying microdata, and the "DP" queries allow policy makers to target specific statistics that will be more accurate in the published data. 

Queries defined in the disclosure avoidance system do not have a one-to-one relationshiop with tables published in the DDP or v20200527 datasets. The queries are used in the noise injection and optimization processes, and the published tables are created from microdata created by those processes. Categories in the published tables can and will differ from those used in the queries. 

The Census Bureau designed seven and five queries to support the production of person tables in the DDP and v20200527, respectively, and these queries received direct PLB allocations (Table X). Query descriptions and PLB allocations are shown in Table X. The _voting age * Hispanic * race * citizenship_ query, which is used for legislative redistricting, received the largest allocation (50%) in the DDP, and the _total population_ query received the largest allocation (30%) in v20200527. 

#### Invariants and Constraints

Invariants and constraints play key roles in the disclosure avoidance system, particularly in the post-processing routines applied to the noisy counts. Invariants are counts computed directly from the Census Edited File (CEF) and are not subject to noise injection. Constraints control the types and ranges of values in the published statistics. 

The Bureau has not yet selected invariants for the 2020 Decennial Census, but it did set four invariants for the DDP and v20200527 datasets. Total population is invariant at the state-level, and total housing units, total group quarters facilities, and total group quarters facilities by type are invariant at the census block-level. These same four statistics were invariant at the _census block-level_ in the 2010 Decennial Census. Additionally, voting age population and occupied housing units (i.e., households) were invariant at the census block-level in 2010. 

Constraints are the set of rules that the data produced by the disclosure avoidance system must follow. For both datasets we analyzed, constraints included non-negativity, integer, and hierarchical consistency. The non-negativity and integer constraints require that all published statistics to positive integer values. The hierarchical consistency constraint imposes consistency among geographic and category hierarchies. For geographic hierarchies, counts for child units must sum to the counts of their parent unit. For category hierarchies, counts child categories must sum to the counts of their parent category. 

Invariants and constraints are not required by the disclosure avoidance system; instead, they are imposed to satisfy the expectations of policy makers and data users. The state-level total population invariant was established to avoid debates and litigation over Congressional reapportionment. The non-negativity and integer constraints are imposed to avoid negative counts or non-integer values for geographic units, since we only count whole persons in the census. These constraints avoid such illogical values. Consistency constraints guarantee that if you sum the male and female totals from any published data table, you will obtain the same sum.

### Disclosure avoidance system

The disclosure avoidance system that generated the DDP and v20200527 consists of three steps: generating counts from the CEF, injecting noise, and post-processing the satisfy invariants and constraints. The first two steps were the same for both datasets, but the post-processing step differed substantially.

#### Generating Counts

The first step produces counts from the CEF. The disclosure avoidance system consumes the CEF, the queries and geographic levels and creates a set of cross-tabulations (or histograms) - one for each combination of query and geographic level. The cells in each cross-tabulation contain the counts of a particular set of categories (e.g., 0-4 year old males) for a given geographic unit. The number of cells in these cross-tabulations may be massive, particularly at the census block level, and the counts in the cells may be small or even zero.

#### Noise Injection

The second step injects noise into the counts generated in the prior step. These "noisy counts" are, by definition, differentially private, but they may not satisfy invariants or constraints. The noise injection step is implemented with three sub-steps.

##### Compute $\epsilon$ for Each Geographic Level * Query Combination

We compute $\epsilon$ for each combination by multiplying the PLB, geographic level fraction, and query fraction:

$$\epsilon = PLB * GeogLevel_{fraction} * Query_{fraction}$$

For the DDP and v20200527, the PLB was 4.0, the geographic level fractions are listed in XXXX, and the query fractions are shown in the XXXX column of Table X.

##### Compute the Scale Parameter for the Statistical Distribution

Noise-injection values are generated by randomly drawing a value from a statistical distribution, typically a Laplace distribution for continuous variables or the geometric distribution for discrete variables (i.e., countable values). The shape of the distribution is controlled by the scale parameter calculated using the following formula: 

$$s = \frac{2}{\epsilon}$$
$\epsilon$ is the geographic level * query value computed in the previous sub-step. The numerator is the sensitivity of the query, which is always 2 for histograms.^[Sensitivity is the value by which a query changes if we make a single modification to the database. Histogram queries have a sensitivity of 2 - if we increase the count in a cell by 1, we must decrease the count in another cell by 1.] 

Scale parameters for the DDP and v20200527 are shown in Table X. Nation and state scale parameters are the same for each query because those geographic levels receive the same fractional allocation. County, census tract group, census tract, census block group, and census block scale parameters are the same because those geographic levels receive the same fractional allocations.

We can compute the standard deviation [NOTE: should I compute std dev, variance or IQR for the paper?] for each distribution as follows:

$$\sigma = \sqrt{2 * s^2}$$
Larger scale parameters represent distributions with higher variances, which yield potentially larger noise values. 

##### Generate and Inject Random Noise in each Cell

For each cell in a particular combination of a geographic level * query, a random value is drawn from the appropriate distribution and added to the cell value. This sum is the noisy count. If we consider the _county_ by _voting age * Hispanic * race_ for the v20200527 dataset, we will take 811,692 random values (3,221 county * 252 unique categories in the query) from a distribution with a scale parameter of 14.4 and an IQR of XXX. Thus, 50% of those random values will fall within the IQR and 50% will fall outside the IQR. 

#### Post-processing

The output of the prior step is a set of noisy, differentially private, histograms---one for each _geographicy level * query_ combination. These histograms are integer-valued but may not satisfy invariants and constraints. Additionally, the set of queries and geographic levels used for noise injection does not match the set of cross-tabulations and geographic levels desired for publication. In order to produce the final dataset that satisfy invariants and constraints, the Census Bureau conducts a series of optimization steps that ultimately create microdata (each record represents a person), which can then be tabulated for publication.

Different post-processing routines were used to generate the DDP and v20200527 datasets. Both routines follow the same general structure in that they start at the national level and work down the geographic hierarchy, successively generating data for finer geographic levels. However, the optimization step for each geographic level differs. 

For the DDP, the algorithm minimized the differences between the noisy detailed histogram and the noisy DP queries, along satisfying invariants, non-negativity, and consistency, in a single optimization step. ISSUES WITH THIS - this is what caused lots of issues identified at CNStat, etc...?

To ameliorate inaccuracies in the DDP, the Census Bureau redesigned the post-processing routine, creating what is now called the "multipass" routine. Instead of optimizing all cells in the detailed and DP queries at one time for a given geographic level, the routine runs multiple optimization steps for each geographic level. In the first pass, the routine optimizes the differences between the noisy detailed histogram and the total population and household/group quarters counts. In the second pass, the routine optimizes differences between the noisy detailed histogram and the _voting age * Hispanic * race_ query, controlling the counts to the results of the first pass. In other words, if we sum the optimized counts from the _voting age * Hispanic * race_ categories, the result will be close to the optimized total population count generated in the first pass. 

The third pass optimizes differences between the noisy detailed histogram and the _age * sex * Hispanic * race_ query, controlling the counts to the results of the second pass. 

These passes are run for each geographic level in the hierarchy. All passes are run for the nation level first, then the state level, and down the hierarchy until they are run for the block level. Essentially, the multipass routine is top-down along two dimensions---the geograhphic hierarchy and the query hierarchy. 







## Data

Describe public health data (sources, unit of geography, age/race/sex)

Describe the differentially private census data (unit of geography, demographic categories used)

## Methods

## Results

## Discussion

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
