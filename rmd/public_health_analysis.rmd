---
title: "Public Health Analysis using DP Data"
author: "David Van Riper"
date: "9/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

Public health scientists and practitioners rely on decennial census data on the sex, age, race, and Hispanic ethnicity for states, counties, cities, and neighborhoods to track a wide range of health outcomes. Decennial data, along with products benchmarked to them (e.g., annual population estimates), provide crucial denominators for tracking disease prevalence and help scientists identify at-risk populations for XXXXX. Poor quality data will limit our ability to track and respond to public health crises. 

For the 2020 Decennial Census, the US Census Bureau is changing its disclosure avoidance system to provide stronger confidentiality protections for respondents. The new system, based on differential privacy, injects noise into nearly all published statistics to XXXXX. This noise injection necessarily makes statistics less accurate to provide enhanced confidentiality protections. Less accurate data, however, may hurt our ability to track health outcomes across a broad variety of sub-populations. 

To better understand the potential impacts the new disclosure avoidance system may have on public health research and monitoring, we will compare XXXXX using three datasets based on the 2010 decennial census - Summary File 1, the 2010 Demonstration Data Product (DDP), and the v20200527 dataset. The latter two datasets were produced by different versions of the new disclosure avoidance system, and Summary File 1 was produced using household swapping for disclosure avoidance. These comparisons will help us understand the potential issues public health scientists may face when using differentially private data.   

## Differential Privacy and the Decennial Census 

In August 2018, the US Census Bureau announced it would adopt a new method to protect respondent confidentiality in the 2020 Decennial Census of Population and Housing (Abowd 2018). Instead of using techniques such as cell suppression or household swapping^[Readers interested in learning about the disclosure avoidance techniques used by the Census Bureau are directed to McKenna (cite her paper)], the Bureau will use a technique based on differential privacy to protect confidentiality. ADD IN QUOTE FROM GARFINKEL ABOUT SEA CHANGE IN DATA PUBLICATION.

Why did the Bureau decide to change its disclosure avoidance system? Bureau scientists executed a reconstruction and re-identification attack on the publicly available tabulations from the 2010 decennial census. Using the database reconstruction theorem (CITE Dinur and Nissim), the Bureau reconstructed 308,745,538 person records from census tract and block data. Each record included the age, sex, race, Hispanic ethnicity, and census block identifier. The Bureau then linked the reconstructed records with a commercial database (which included names) using age, sex, and block identifier. Approximately forty-five percent (139 million) of the reconstructed records matched a record in the commercial database. Finally, the Bureau attempted to link these 139 million records to the confidential microdata on all attributes---census block identifier, name, age, sex, race, and Hispanic ethnicity. For 52 million records (seventeen percent of the US resident population in 2010), the Bureau confirmed that the two records referred to the same person.

Results of this attack pushed the Bureau to develop and implement a new disclosure avoidance technique that provide stronger confidentiality protections than prior methods. The new technique is based on differential privacy, which provides a mathematically provable lower bound on the amount of private information leaked when statistics are published (CITE Dwork et al). Algorithms that satisfy differential privacy typically follow a pattern of calculating cross-tabulations from the confidential data and injecting noise drawn from a statistical distribution in the cells of the cross-tabulation. The shape of the statistical distribution is determined by parameters established by the data producer prior to the initial cross-tabulation.^[Traditional disclosure avoidance techniques, such as swapping, target statistically unique individuals or households identified after generating the initial cross-tabulations. After identifying these individuals or households, the Bureau applies swapping and then re-creates the cross-tabulations from the swapped microdata. Swap rules and rates are secret and have never been released to the general public (CITE MCKENNA? or BOYD?). Hansen (CITE NYTimes article) found evidence of swapping when he examined the demographic characteristics of the census block containing Liberty Island in New York City.]          

The Bureau's new disclosure avoidance system relies on many parameters that must be established before execution, and the values of these parameters influence the accuracy and utility of the published data along with the privacy protection afforded respondents. In the case of the 2020 decennial census, the parameters will be set by the Bureau's Data Stewardship Executive Policy (DSEP) committee. DSEP will select parameters that inherently privilege particular statistics over others, and it is crucial that data users understand this fact.  

### Policy Decisions

Disclosure avoidance algorithms require parameters that control the amount of noise, suppression, or swapping applied to the input data. Values for these parameters impact the quality and accuracy of the output data, and it is critical that data users understand both the significance of the parameters and their possible range of values. This section discusses the Top Down Algorithm's parameters and the values used to generate the DDP and the v20200527 datasets. 

#### Global Privacy Loss Budget

The global privacy loss budget ($\epsilon$) controls the trade-off between the privacy afforded to Census respondents and the accuracy of the published data. Values for $\epsilon$ range from 0 to infinity, with 0 representing perfect privacy/no accuracy and infinity representing no privacy/perfect accuracy. After establishing the global PLB, it is then allocated to geographic levels and queries. Geographic levels or queries that receive larger fractions will be more accurate. 

For both the DDP and v20200527 datasets, the Census Bureau's Data Stewardship Executive Policy Committee established a PLB of 4.0 for person-based tables.^[The DDP included housing unit and household data. A PLB of 2.0 was provided housing unit-based queries. The v20200527 only includes person data.] The PLB was then allocated to combinations of geographic levels and queries, and those allocations ultimately control the magnitude of the noise injected into counts.  

#### Geographic Levels

If we think of the cross-tabulations into which noise is injected as a set of rows and columns, the geographic levels define the rows. Each row in a cross-tabulation is a geographic unit within a geographic level (e.g., Autauga County, Alabama, is a geographic unit in the County geographic level). For both the DDP and v20200527 datasets, seven geographic levels in the Census Bureau's hierarchy received direct allocations of the PLB. The nation and state received 20% each, and the remaining five levels (county, census tract group^[The census tract group is not a standard unit in the Census Bureau's geographic hierarchy. It was created specifically for the disclosure avoidance system to control the number of child units for each county], census tract, block group, and block) received 12% each. Geographic levels that receive no direct PLB allocation accumulate accuracy from the units that comprise them.

#### Queries 

If geographic levels define the rows of a cross-tabulation, then queries define the columns. Queries are essentially combinations of demographic variables, and the PLB is allocated to these queries. The disclosure avoidance system defined two types of queries. "Detailed" queries consist of all unique combinations of variables, and "DP" queries are specific combinations of variables. The "detailed" queries allow the Bureau to reconstruct the underlying microdata, and the "DP" queries allow policy makers to target specific statistics that will be more accurate in the published data. 

Queries defined in the disclosure avoidance system do not have a one-to-one relationship with tables published in the DDP or v20200527 datasets. The queries are used in the noise injection and optimization processes, and the published tables are created from microdata created by those processes. Categories in the published tables can and will differ from those used in the queries. 

The Census Bureau designed seven and five queries to support the production of person tables in the DDP and v20200527, respectively, and these queries received direct PLB allocations (Table X). Query descriptions and PLB allocations are shown in Table X. The _voting age * Hispanic * race * citizenship_ query, which is used for legislative redistricting, received the largest allocation (50%) in the DDP, and the _total population_ query received the largest allocation (30%) in v20200527. 

#### Invariants and Constraints

Invariants and constraints play key roles in the disclosure avoidance system, particularly in the post-processing routines applied to the noisy counts. Invariants are counts computed directly from the Census Edited File (CEF) and are not subject to noise injection. Constraints control the types and ranges of values in the published statistics. 

The Bureau has not yet selected invariants for the 2020 Decennial Census, but it did set four invariants for the DDP and v20200527 datasets. Total population is invariant at the state-level, and total housing units, total group quarters facilities, and total group quarters facilities by type are invariant at the census block-level. These same four statistics were invariant at the _census block-level_ in the 2010 Decennial Census. Additionally, voting age population and occupied housing units (i.e., households) were invariant at the census block-level in 2010. 

Constraints are the set of rules that the data produced by the disclosure avoidance system must follow. For both datasets we analyzed, constraints included non-negativity, integer, and hierarchical consistency. The non-negativity and integer constraints require that all published statistics to positive integer values. The hierarchical consistency constraint imposes consistency among geographic and category hierarchies. For geographic hierarchies, counts for child units must sum to the counts of their parent unit. For category hierarchies, counts child categories must sum to the counts of their parent category. 

Invariants and constraints are not required by the disclosure avoidance system; instead, they are imposed to satisfy the expectations of policy makers and data users. The state-level total population invariant was established to avoid debates and litigation over Congressional reapportionment. The non-negativity and integer constraints are imposed to avoid negative counts or non-integer values for geographic units, since we only count whole persons in the census. These constraints avoid such illogical values. Consistency constraints guarantee that if you sum the male and female totals from any published data table, you will obtain the same sum.

### Disclosure avoidance system

The disclosure avoidance system that generated the DDP and v20200527 consists of three steps: generating counts from the CEF, injecting noise, and post-processing the satisfy invariants and constraints. The first two steps were the same for both datasets, but the post-processing step differed substantially.

#### Generating Counts

The first step produces counts from the CEF. The disclosure avoidance system consumes the CEF, the queries and geographic levels and creates a set of cross-tabulations (or histograms) - one for each combination of query and geographic level. The cells in each cross-tabulation contain the counts of a particular set of categories (e.g., 0-4 year old males) for a given geographic unit. The number of cells in these cross-tabulations may be massive, particularly at the census block level, and the counts in the cells may be small or even zero.

#### Noise Injection

The second step injects noise into the counts generated in the prior step. These "noisy counts" are, by definition, differentially private, but they may not satisfy invariants or constraints. The noise injection step is implemented with three sub-steps.

##### Compute $\epsilon$ for Each Geographic Level * Query Combination

We compute $\epsilon$ for each combination by multiplying the PLB, geographic level fraction, and query fraction:

$$\epsilon = PLB * GeogLevel_{fraction} * Query_{fraction}$$

For the DDP and v20200527, the PLB was 4.0, the geographic level fractions are listed in XXXX, and the query fractions are shown in the XXXX column of Table X.

##### Compute the Scale Parameter for the Statistical Distribution

Noise-injection values are generated by randomly drawing a value from a statistical distribution, typically a Laplace distribution for continuous variables or the geometric distribution for discrete variables (i.e., countable values). The shape of the distribution is controlled by the scale parameter calculated using the following formula: 

$$s = \frac{2}{\epsilon}$$
$\epsilon$ is the geographic level * query value computed in the previous sub-step. The numerator is the sensitivity of the query, which is always 2 for histograms.^[Sensitivity is the value by which a query changes if we make a single modification to the database. Histogram queries have a sensitivity of 2 - if we increase the count in a cell by 1, we must decrease the count in another cell by 1.] 

Scale parameters for the DDP and v20200527 are shown in Table X. Nation and state scale parameters are the same for each query because those geographic levels receive the same fractional allocation. County, census tract group, census tract, census block group, and census block scale parameters are the same because those geographic levels receive the same fractional allocations.

We can compute the standard deviation for each distribution as follows:

$$\sigma = \sqrt{2 * s^2}$$
For the Laplace distribution, approximately 75% of the random values will fall within 1 standard deviation of the mean as compared to 68% of random values in the normal distribution. But, the tails of the Laplace distribution are thicker than the normal distribution, increasing the probability of drawing a random value that is 3 or 4 times the standard deviation. (SHOULD I ADD PERCENTAGES TO SHOW THIS).   

<!-- Larger scale parameters represent distributions with higher variances, which yield potentially larger noise values.  -->

##### Generate and Inject Random Noise in each Cell

For each cell in a particular combination of a geographic level * query, a random value is drawn from the appropriate distribution and added to the cell value. This sum is the noisy count. If we consider the _county_ by _voting age * Hispanic * race_ for the v20200527 dataset, we will take 811,692 random values (3,221 county * 252 unique categories in the query) from a distribution with a scale parameter of 14.4 and an IQR of XXX. Thus, 50% of those random values will fall within the IQR and 50% will fall outside the IQR. 

#### Post-processing

The output of the prior step is a set of noisy, differentially private, histograms---one for each _geographic level * query_ combination. These histograms are integer-valued but may not satisfy invariants and constraints. Additionally, the set of queries and geographic levels used for noise injection does not match the set of cross-tabulations and geographic levels desired for publication. In order to produce the final dataset that satisfy invariants and constraints, the Census Bureau conducts a series of optimization steps that ultimately create microdata (each record represents a person), which can then be tabulated for publication.

Different post-processing routines were used to generate the DDP and v20200527 datasets. Both routines follow the same general structure in that they start at the national level and work down the geographic hierarchy, successively generating data for finer geographic levels. However, the optimization step for each geographic level differs. 

For the DDP, the algorithm minimized the differences between the noisy detailed histogram and the noisy DP queries, along with satisfying invariants, non-negativity, and consistency, in a single optimization step (Figure X, Panel Z). The algorithm first optimized the nation-level queries, and then moved down the geographic hierarchy (Figure X, Panel Y) until it produced the optimized block-level queries. Those queries were then converted to microdata that were tabulated for publication. ISSUES WITH THIS - this is what caused lots of issues identified at CNStat, etc...?

To ameliorate inaccuracies in the DDP, the Census Bureau redesigned the post-processing routine, creating what is now called the _multipass_ routine. This new routine was used on the v20200527 dataset. Instead of optimizing all cells in the detailed and DP queries at one time for a given geographic level, the routine runs multiple optimization steps for each geographic level. In the first pass, the routine optimizes the differences between the noisy detailed histogram and the total population and household/group quarters counts. In the second pass, the routine optimizes differences between the noisy detailed histogram and the _voting age * Hispanic * race_ query, controlling the counts to the results of the first pass (Figure Y, Panel Z). In other words, if we sum the optimized counts from the _voting age * Hispanic * race_ categories, the result will be close to the optimized total population count generated in the first pass. 

The third pass optimizes differences between the noisy detailed histogram and the _age * sex * Hispanic * race_ query, controlling the counts to the results of the second pass. 

These passes are run for each geographic level in the geographic hierarchy (Figure Y, Panel Y). All passes are run for the nation level first, then the state level, and down the hierarchy until they are run for the block level. Essentially, the multipass routine is top-down along two dimensions---the geographic hierarchy and the query hierarchy. By adding the query hierarchy and the extra optimization steps for queries, the Bureau may prioritize particular use cases. For the v20200527 dataset, the top query priority was total population counts and counts of persons in households or group quarters, and the second and third query priorities were counts that support redistricting and population estimates, respectively. 

## Data



Describe public health data (sources, unit of geography, age/race/sex)

Describe the differentially private/2010 Summary File 1 census data (unit of geography, demographic categories used)

## Methods

What are we going to compute using multiple denominators?

## Results

## Discussion

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
